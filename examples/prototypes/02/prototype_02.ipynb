{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import trimesh\n",
    "from monai.data import Dataset\n",
    "from monai.config import print_config\n",
    "from transforms_templates.utils.utils import watermark, wide_notebook\n",
    "from transforms_templates.utils.log import log\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# autoreload python modules on the fly when its source is changed\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 0.3.0\n",
      "Python version: 3.7.5 (default, Apr 19 2020, 20:18:17)  [GCC 9.2.1 20191008]\n",
      "OS version: Linux (5.3.0-64-generic)\n",
      "Numpy version: 1.19.2\n",
      "Pytorch version: 1.4.0\n",
      "MONAI flags: HAS_EXT = True, USE_COMPILED = False\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "Nibabel version: 3.1.1\n",
      "scikit-image version: 0.17.2\n",
      "Pillow version: 6.2.2\n",
      "Tensorboard version: 2.4.0a20201021\n",
      "gdown version: 3.12.2\n",
      "TorchVision version: 0.5.0\n",
      "ITK version: 5.1.0\n",
      "tqdm version: 4.50.2\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n",
      "virtualenv:     (transforms_templates) \n",
      "python:         3.7.5\n",
      "hostname:       GA-970A-UD3\n",
      "nvidia driver:  b'435.21'\n",
      "torch:          1.4.0\n",
      "trimesh:        3.8.11\n",
      "transforms_templates: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:70% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_config()\n",
    "\n",
    "_ = watermark(packages=['python', 'virtualenv', 'nvidia', 'cudnn', 'hostname', 'torch', 'trimesh', 'transforms_templates'])\n",
    "wide_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(img, figsize=(8, 8), factor=1 / 255):\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    # ch, h, w --> h, w, ch\n",
    "    img = img.transpose(1, 2, 0)\n",
    "    img = img * factor\n",
    "    ax.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Data dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup data directory\n",
    "\n",
    "DIR_DATA = Path(\"/media/Linux_4Tb/synth3D/tablets_30\")\n",
    "assert DIR_DATA.exists()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d = (DIR_DATA / 'corrupted')\n",
    "train_ply_files = sorted((DIR_DATA / 'corrupted').glob('*.ply'))\n",
    "\n",
    "def get_corresponding_png_file(fn, foreshortening='top', kind='rgb'):\n",
    "    assert foreshortening in ['top', 'left', 'right']\n",
    "    assert kind in ['rgb', 'depth']\n",
    "    base = fn.with_suffix('').name\n",
    "    return fn.parent.parent / 'renders' / f'{base}_{foreshortening}_{kind}.png'\n",
    "\n",
    "def get_corresponding_meta_info_file(fn, foreshortening='top'):\n",
    "    assert foreshortening in ['top', 'left', 'right']\n",
    "    base = fn.with_suffix('').name\n",
    "    return fn.parent.parent / 'renders' / f'{base}_{foreshortening}_meta_info.json'\n",
    "\n",
    "def get_files_dict(fn):\n",
    "    return {'mesh': fn, 'image2d': get_corresponding_png_file(fn), 'image2d_meta_dict': get_corresponding_meta_info_file(fn)}\n",
    "\n",
    "data_dicts = [get_files_dict(fn) for fn in train_ply_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Dataset(data=data_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mesh': PosixPath('/media/Linux_4Tb/synth3D/tablets_30/corrupted/tablets_30_00000.ply'),\n",
       " 'image2d': PosixPath('/media/Linux_4Tb/synth3D/tablets_30/renders/tablets_30_00000_top_rgb.png'),\n",
       " 'image2d_meta_dict': PosixPath('/media/Linux_4Tb/synth3D/tablets_30/renders/tablets_30_00000_top_meta_info.json')}"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True, True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[0]['mesh'].exists(), ds[0]['image2d'].exists(), ds[0]['image2d_meta_dict'].exists()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Loader as transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from transforms_templates.transforms.io.mesh import LoadPLYd\n",
    "#from transforms_templates.transforms.io.image2d import LoadPNGandJSONd\n",
    "#from transforms_templates.transforms.compose import Compose\n",
    "\n",
    "#from monai.transforms import LoadDatad, LoadPNG\n",
    "#from monai.config import KeysCollection\n",
    "#from monai.transforms import Transform\n",
    "\n",
    "import tt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test loader transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tfms_load = tt.Compose([\n",
    "    tt.LoadPLYd(keys=['mesh']),\n",
    "    tt.LoadPNGandJSONd(keys=['image2d'], overwriting=True),\n",
    "    tt.Transposed(keys=['image2d'], indices=[2, 0, 1]),\n",
    "    tt.DebugDict(keys=['mesh', 'image2d'])\n",
    "])\n",
    "\n",
    "tfms_convert_1 = tt.Compose([\n",
    "    tt.ScaleIntensityDict(keys=['image2d'], minv=None,maxv=None, factor=-254/255),\n",
    "    tt.RandFlipX(keys=['mesh', 'image2d'], prob=0.99, image_spatial_axis=1),\n",
    "    # image_spatial_axis: for 2D images axis starts without channel (ch, 0-h, 1-w), e.g. 1 - width\n",
    "    # https://github.com/Project-MONAI/MONAI/blob/master/monai/transforms/spatial/array.py#L262  \n",
    "    tt.ToPointCloud(keys=['mesh'], new_keys=['pc'], method='centers',\n",
    "                    features_from_vertices=['red', 'green', 'blue'],\n",
    "                    labels_from_faces=['shape_id']\n",
    "                   ),\n",
    "    tt.SamplePoints(keys=['pc'], num_points=10000),\n",
    "    tt.CropRect(keys=['pc'], sizes=[-25, 10, -5.5, 25, 40, 5.5]), # xyzxyz\n",
    "    tt.DebugDict(keys=['pc', 'image2d'])\n",
    "])\n",
    "\n",
    "tfms_convert_2 = tt.Compose([\n",
    "    tt.ToSparseVoxels(keys=['pc'],\n",
    "                      coords_range=[-25, 10, -5.5, 25, 40, 5.5],\n",
    "                      voxel_size=[1, 2.,  0.5],\n",
    "                      add_local_pos=True,\n",
    "                      new_keys_prefixes = ['sp']),\n",
    "    tt.ToTensorD(keys=['sp_coords', 'sp_features', 'sp_shape_id']),\n",
    "    tt.DebugDict(keys=None)\n",
    "])\n",
    "\n",
    "# all transforms\n",
    "tfms = tt.Compose(tfms_load.transforms + tfms_convert_1.transforms + tfms_convert_2.transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test transfroms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mesh': PosixPath('/media/Linux_4Tb/synth3D/tablets_30/corrupted/tablets_30_00000.ply'),\n",
       " 'image2d': PosixPath('/media/Linux_4Tb/synth3D/tablets_30/renders/tablets_30_00000_top_rgb.png'),\n",
       " 'image2d_meta_dict': PosixPath('/media/Linux_4Tb/synth3D/tablets_30/renders/tablets_30_00000_top_meta_info.json')}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# object before transformation\n",
    "ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debug 1\n",
      "  keys: ['mesh', 'image2d', 'image2d_meta_dict', 'mesh_meta_dict']\n",
      "  self.keys: ('mesh', 'image2d')\n",
      "'mesh':\n",
      "<trimesh.Trimesh(vertices.shape=(20424, 3), faces.shape=(40836, 3))>\n",
      "\n",
      "  x                        shape: (20424,)              dtype: float64        min:  -26.40680,  max:   27.44418,  mean:    0.08402\n",
      "  y                        shape: (20424,)              dtype: float64        min:   12.92263,  max:   43.61013,  mean:   31.67863\n",
      "  z                        shape: (20424,)              dtype: float64        min:   12.92263,  max:   43.61013,  mean:   31.67863\n",
      "  vertex_features:\n",
      "    red                      shape: (20424,)              dtype: uint8          min:  128.00000,  max:  128.00000,  mean:  128.00000\n",
      "    green                    shape: (20424,)              dtype: uint8          min:  128.00000,  max:  128.00000,  mean:  128.00000\n",
      "    blue                     shape: (20424,)              dtype: uint8          min:  128.00000,  max:  128.00000,  mean:  128.00000\n",
      "    alpha                    shape: (20424,)              dtype: uint8          min:  255.00000,  max:  255.00000,  mean:  255.00000\n",
      "    shape_id                 shape: (20424,)              dtype: int8           min:    0.00000,  max:    7.00000,  mean:    3.48928\n",
      "  face_features:\n",
      "    stl                      shape: (40836,)              dtype: uint16         min:    0.00000,  max:    0.00000,  mean:    0.00000\n",
      "    shape_id                 shape: (40836,)              dtype: int8           min:    0.00000,  max:    7.00000,  mean:    3.49153\n",
      "'image2d'                shape: (4, 256, 256)         dtype: float32        min:   48.00000,  max:  255.00000,  mean:  186.81006\n",
      "\n"
     ]
    }
   ],
   "source": [
    "o = tfms_load(ds[0], debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['mesh', 'image2d', 'image2d_meta_dict', 'mesh_meta_dict'])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#log(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show_image(o['image2d'], factor=1 / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debug 1\n",
      "  keys: ['image2d', 'image2d_meta_dict', 'mesh_meta_dict', 'pc']\n",
      "  self.keys: ('pc', 'image2d')\n",
      "'pc':\n",
      "x                        shape: (9177,)               dtype: float32        min:  -24.99984,  max:   24.99968,  mean:    0.48211\n",
      "y                        shape: (9177,)               dtype: float32        min:   12.94880,  max:   43.59680,  mean:   32.57383\n",
      "z                        shape: (9177,)               dtype: float32        min:   -5.49804,  max:    5.49940,  mean:   -0.03761\n",
      "features                 shape: (9177, 6)             dtype: float32        min:   -0.99999,  max:  128.00000,  mean:   64.00053\n",
      "shape_id                 shape: (9177,)               dtype: int8           min:    0.00000,  max:    7.00000,  mean:    3.41528\n",
      "features_original_keys: ['red', 'green', 'blue', 'nx', 'ny', 'nz']\n",
      "labels_keys: ['shape_id']\n",
      "'image2d'                shape: (4, 256, 256)         dtype: float32        min:    0.18824,  max:    1.00000,  mean:    0.73259\n",
      "\n"
     ]
    }
   ],
   "source": [
    "b = tfms_convert_1(o, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show_image(b['image2d'], factor=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debug 1\n",
      "  keys: ['image2d', 'image2d_meta_dict', 'mesh_meta_dict', 'sp_coords', 'sp_features', 'sp_shape_id', 'sp_features_original_keys', 'sp_labels_keys']\n",
      "  self.keys: (None,)\n",
      "   image2d                  shape: (4, 256, 256)         dtype: float32        min:    0.18824,  max:    1.00000,  mean:    0.73259\n",
      "image2d_meta_dict:\n",
      "   filename_or_obj          /media/Linux_4Tb/synth3D/tablets_30/renders/tablets_30_00000_top_rgb.png\n",
      "   spatial_shape            (256, 256)\n",
      "   format                   'PNG'\n",
      "   mode                     'RGBA'\n",
      "   width                    256\n",
      "   height                   256\n",
      "info:\n",
      "   Software                 'Matplotlib version3.3.2, https://matplotlib.org/'\n",
      "   dpi                      (100, 100)\n",
      "camera_info:\n",
      "   projection_matrix        [[3.7290582683229117, 0.0, 0.0, 0.0], [0.0, 3.7290582683229117, 0.0, 0.0], [0.0, 0.0, -1.0, -0.1], [0.0, 0.0, -1.0, 0.0]]\n",
      "   pos                      [[0.5207025366977089, 0.0, 0.0, 0.06674625131234299], [0.0, 0.5470937647723557, 0.0, -0.04717951268335549], [0.0, 0.0, 0.22825356909249078, 2.0187850111351904], [0.0, 0.0, 0.0, 1.0]]\n",
      "   mesh_transform           [[0.02997280864274262, 0.0008099670012058981, -0.0009872666926877965, 0.0], [-0.0008104059528913173, 0.02998905203889443, 0.0, -0.3], [0.0009869064074427177, 2.6669560161517105e-05, 0.029983750673948536, 0.0], [0.0, 0.0, 0.0, 1.0]]\n",
      "mesh_meta_dict:\n",
      "   meta                     1\n",
      "   sp_coords                shape: (9177, 3)             dtype: torch.int64    min:          0,  max:         49,  mean:   15.40013\n",
      "   sp_features              shape: (9177, 9)             dtype: torch.float32  min:  -25.49995,  max:  128.00000,  mean:   41.03569\n",
      "   sp_shape_id              shape: (9177,)               dtype: torch.int8     min:    0.00000,  max:    7.00000,  mean:    3.41528\n",
      "   sp_features_original_keys['red', 'green', 'blue', 'nx', 'ny', 'nz', 'dx', 'dy', 'dz']\n",
      "   sp_labels_keys           ['shape_id']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "c = tfms_convert_2(b, debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Dataset(data=data_dicts, transform=tfms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "o = ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   image2d                  shape: (4, 256, 256)         dtype: float32        min:    0.18824,  max:    1.00000,  mean:    0.73259\n",
      "image2d_meta_dict:\n",
      "   filename_or_obj          /media/Linux_4Tb/synth3D/tablets_30/renders/tablets_30_00000_top_rgb.png\n",
      "   spatial_shape            (256, 256)\n",
      "   format                   'PNG'\n",
      "   mode                     'RGBA'\n",
      "   width                    256\n",
      "   height                   256\n",
      "info:\n",
      "   Software                 'Matplotlib version3.3.2, https://matplotlib.org/'\n",
      "   dpi                      (100, 100)\n",
      "camera_info:\n",
      "   projection_matrix        [[3.7290582683229117, 0.0, 0.0, 0.0], [0.0, 3.7290582683229117, 0.0, 0.0], [0.0, 0.0, -1.0, -0.1], [0.0, 0.0, -1.0, 0.0]]\n",
      "   pos                      [[0.5207025366977089, 0.0, 0.0, 0.06674625131234299], [0.0, 0.5470937647723557, 0.0, -0.04717951268335549], [0.0, 0.0, 0.22825356909249078, 2.0187850111351904], [0.0, 0.0, 0.0, 1.0]]\n",
      "   mesh_transform           [[0.02997280864274262, 0.0008099670012058981, -0.0009872666926877965, 0.0], [-0.0008104059528913173, 0.02998905203889443, 0.0, -0.3], [0.0009869064074427177, 2.6669560161517105e-05, 0.029983750673948536, 0.0], [0.0, 0.0, 0.0, 1.0]]\n",
      "mesh_meta_dict:\n",
      "   meta                     1\n",
      "   sp_coords                shape: (9141, 3)             dtype: torch.int64    min:          0,  max:         49,  mean:   15.39460\n",
      "   sp_features              shape: (9141, 9)             dtype: torch.float32  min:  -25.49995,  max:  128.00000,  mean:   41.02792\n",
      "   sp_shape_id              shape: (9141,)               dtype: torch.int8     min:    0.00000,  max:    7.00000,  mean:    3.42173\n",
      "   sp_features_original_keys['red', 'green', 'blue', 'nx', 'ny', 'nz', 'dx', 'dy', 'dz']\n",
      "   sp_labels_keys           ['shape_id']\n"
     ]
    }
   ],
   "source": [
    "log(o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collate/merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from fastai_sparse.data_items import extract_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex1 = ds[0]\n",
    "ex2 = ds[1]\n",
    "ex3 = ds[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [ex1, ex2, ex3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: dtypes are converted in transforms before\n",
    "# TODO: work with numpy (work with tensors now)\n",
    "\n",
    "\n",
    "class Collater():\n",
    "    \"\"\"\n",
    "    For use in configs (hydra)\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 as_list = ['id', 'num_points'],\n",
    "                 as_stack = ['image2d'],  # tensor [(C, H, W), (C, H, W), ] ---> [B, C, H, W, ...]\n",
    "                 as_pack=['sp_features', 'sp_shape_id'],\n",
    "                 as_pack_with_index=['sp_coords'],  # for SparseConNet\n",
    "                 num_points_source_key='sp_coords',\n",
    "                 ):\n",
    "        self.as_list = as_list\n",
    "        self.as_stack = as_stack\n",
    "        self.as_pack = as_pack\n",
    "        self.as_pack_with_index = as_pack_with_index\n",
    "        self.num_points_source_key = num_points_source_key\n",
    "        \n",
    "    # __call__ ?\n",
    "    def collate(self, examples):\n",
    "        res = {}\n",
    "    \n",
    "        for key in self.as_pack_with_index:\n",
    "            a = [d[key] for d in examples]\n",
    "            # TODO: \n",
    "            ones = torch.from_numpy(np.vstack([idx * np.ones((x.shape[0], 1), dtype=\"int64\") for idx, x in enumerate(a)]))\n",
    "            a = torch.cat(a, dim=0)\n",
    "            a = torch.cat([a, ones], dim=1)\n",
    "            res[key] = a\n",
    "\n",
    "        for key in self.as_pack:\n",
    "            a = [d[key] for d in examples]\n",
    "            a = torch.cat(a, dim=0)\n",
    "            res[key] = a\n",
    "\n",
    "        if \"num_points\" in self.as_list:\n",
    "            num_points = [len(d[self.num_points_source_key]) for d in examples]\n",
    "            res[\"num_points\"] = num_points\n",
    "\n",
    "        return res\n",
    "\n",
    "    def num_points_of_example(self, example, key=['sp_coords']):\n",
    "        # TODO: as transform which fill aditioanal key 'num_points'\n",
    "        return len(example[key])\n",
    "\n",
    "    \n",
    "def custom_merge_fn(\n",
    "    examples,              # List of examples(items) of dataset to be merged\n",
    "    # separate_labels=True,  # Return {'x1': any, 'x2': any, 'y': any} or ({'x1': any, 'x2': any }, y)  if True\n",
    "    # TODO: names of params\n",
    "    # https://github.com/facebookresearch/pytorch3d/blob/master/docs/notes/batching.md\n",
    "\n",
    "    as_list = ['id', 'num_points'],\n",
    "    as_stack = ['image2d'],  # tensor [(C, H, W), (C, H, W), ] ---> [B, C, H, W, ...]\n",
    "    as_pack_with_index=['sp_coords'],  # for SparseConNet\n",
    "    as_pack=['sp_features', 'sp_shape_id'],\n",
    "    num_points_source_key='sp_coords',\n",
    "):\n",
    "    \n",
    "    res = {}\n",
    "    \n",
    "    for key in as_pack_with_index:\n",
    "        a = [d[key] for d in examples]\n",
    "        ones = torch.from_numpy(np.vstack([idx * np.ones((x.shape[0], 1), dtype=\"int64\") for idx, x in enumerate(a)]))\n",
    "        a = torch.cat(a, dim=0)\n",
    "        a = torch.cat([a, ones], dim=1)\n",
    "        res[key] = a\n",
    "    \n",
    "    for key in as_pack:\n",
    "        a = [d[key] for d in examples]\n",
    "        a = torch.cat(a, dim=0)\n",
    "        res[key] = a\n",
    "    \n",
    "    if \"num_points\" in as_list:\n",
    "        num_points = [len(d[num_points_source_key]) for d in examples]\n",
    "        res[\"num_points\"] = num_points\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9151, 9222, 9037]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(d['sp_coords']) for d in examples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = custom_merge_fn(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "collater = Collater()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = collater.collate(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sp_coords                shape: (27410, 4)            dtype: torch.int64    min:          0,  max:         49,  mean:   11.64326\n",
      "   sp_features              shape: (27410, 9)            dtype: torch.float32  min:  -25.49997,  max:  128.00000,  mean:   40.97920\n",
      "   sp_shape_id              shape: (27410,)              dtype: torch.int8     min:    0.00000,  max:    7.00000,  mean:    3.46738\n",
      "   num_points               [9151, 9222, 9037]\n"
     ]
    }
   ],
   "source": [
    "log(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transforms_templates.collate.collate import Collater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "212.667px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
